{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Diffusion-based Super-Resolution for EuroSAT\n",
        "\n",
        "Training diffusion models for 13-channel multispectral satellite imagery super-resolution.\n",
        "\n",
        "**Current Best Result:** 19.31 dB PSNR, 0.7379 SSIM (epoch 55)"
      ],
      "metadata": {
        "id": "title"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "setup_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install -q torchgeo lpips"
      ],
      "metadata": {
        "id": "install_deps",
        "outputId": "c6e25586-186b-494e-f4ca-0710844f2630",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m650.7/650.7 kB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m241.8/241.8 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m859.3/859.3 kB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m846.0/846.0 kB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m165.6/165.6 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m93.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m849.5/849.5 kB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m760.5/760.5 kB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone repository (if in Colab)\n",
        "# !git clone https://github.com/YOUR_USERNAME/diffusion-sr-eurosat.git\n",
        "# %cd diffusion-sr-eurosat\n",
        "\n",
        "# If running locally, just navigate to project directory\n",
        "# %cd /path/to/diffusion-sr-eurosat"
      ],
      "metadata": {
        "id": "clone_repo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive for data and checkpoints\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mount_drive",
        "outputId": "fd1681ab-130a-4248-f1b0-ebc93d690143",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add project root to path\n",
        "import sys\n",
        "sys.path.append('.')"
      ],
      "metadata": {
        "id": "autoreload",
        "outputId": "9de08eb4-d818-4852-e3be-8e694f8d111a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'imp'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1254510460.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Enable auto-reload for module changes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'load_ext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'autoreload'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'autoreload'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Add project root to path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2416\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2417\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2418\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2419\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-57>\u001b[0m in \u001b[0;36mload_ext\u001b[0;34m(self, module_str)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/magics/extension.py\u001b[0m in \u001b[0;36mload_ext\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodule_str\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mUsageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Missing module name.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextension_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'already loaded'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/extensions.py\u001b[0m in \u001b[0;36mload_extension\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodule_str\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mprepended_to_syspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipython_extension_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                     \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipython_extension_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                         print((\"Loading extensions from {dir} is deprecated. \"\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/extensions/autoreload.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimportlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msource_from_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mimp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;31m#------------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'imp'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "imports_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "# Import from our modules\n",
        "from configs.config import BaseConfig\n",
        "from src.data.dataset import get_dataloader\n",
        "from src.models.unet import ConditionalUNet\n",
        "from src.models.diffusion import Scheduler\n",
        "from src.training.train import train\n",
        "from src.training.sample import sampling\n",
        "from src.evaluation.metrics import metrics\n",
        "from src.utils.visualization import visualize_and_save_samples\n",
        "from src.utils.helpers import find_latest_model\n",
        "\n",
        "print(\"âœ… All imports successful!\")"
      ],
      "metadata": {
        "id": "imports"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuration"
      ],
      "metadata": {
        "id": "config_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create configuration\n",
        "config = BaseConfig()\n",
        "\n",
        "# Override any settings for this experiment\n",
        "# config.EPOCHS = 200\n",
        "# config.BATCH_SIZE = 256\n",
        "# config.LR = 1e-4\n",
        "\n",
        "print(f\"Device: {config.DEVICE}\")\n",
        "print(f\"Dataset: {config.DATASET}\")\n",
        "print(f\"Batch Size: {config.BATCH_SIZE}\")\n",
        "print(f\"Epochs: {config.EPOCHS}\")\n",
        "print(f\"Learning Rate: {config.LR}\")\n",
        "print(f\"Output Directory: {config.OUTPUT_DIR}\")"
      ],
      "metadata": {
        "id": "config"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize Model & Data"
      ],
      "metadata": {
        "id": "init_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create output directories\n",
        "if config.TRAIN:\n",
        "    os.makedirs(config.OUTPUT_DIR, exist_ok=True)\n",
        "    os.makedirs(config.DATASET_PATH, exist_ok=True)\n",
        "    print(f\"Output directory: {config.OUTPUT_DIR}\")\n",
        "\n",
        "# Get dataloader\n",
        "dataloader = get_dataloader(config)\n",
        "print(f\"âœ… Dataloader created: {len(dataloader)} batches\")\n",
        "\n",
        "# Get validation batch\n",
        "val_high_res_img, val_low_res_img = next(iter(dataloader))\n",
        "val_high_res_img = val_high_res_img[:config.NUM_EVAL_SAMPLES].to(config.DEVICE)\n",
        "val_low_res_img = val_low_res_img[:config.NUM_EVAL_SAMPLES].to(config.DEVICE)\n",
        "print(f\"âœ… Validation batch: {val_high_res_img.shape}\")"
      ],
      "metadata": {
        "id": "init_data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "model = ConditionalUNet(config).to(config.DEVICE)\n",
        "\n",
        "# Initialize optimizer\n",
        "optimizer = optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=config.LR,\n",
        "    weight_decay=config.WEIGHT_DECAY\n",
        ")\n",
        "\n",
        "# Initialize scheduler\n",
        "scheduler = Scheduler()\n",
        "alphas_cumprod = scheduler.get_linear_beta_scheduler(\n",
        "    config.TIMESTEPS,\n",
        "    config.DEVICE\n",
        ")\n",
        "\n",
        "# Initialize metrics\n",
        "psnr_metric = metrics.PSNR(data_range=2.0)  # [-1, 1] range\n",
        "ssim_metric = metrics.SSIM(data_range=2.0)\n",
        "lpips_metric = metrics.LPIPS()\n",
        "\n",
        "print(f\"âœ… Model initialized: {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
        "print(f\"âœ… Optimizer: AdamW (lr={config.LR})\")\n",
        "print(f\"âœ… Scheduler: Linear beta ({config.TIMESTEPS} timesteps)\")"
      ],
      "metadata": {
        "id": "init_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load existing model if in inference mode\n",
        "if not config.TRAIN:\n",
        "    if config.MODEL_PATH is None:\n",
        "        # Auto-detect latest model\n",
        "        config.MODEL_PATH = find_latest_model(config.PROJECT_ROOT)\n",
        "\n",
        "    if config.MODEL_PATH and os.path.exists(config.MODEL_PATH):\n",
        "        checkpoint = torch.load(config.MODEL_PATH, map_location=config.DEVICE)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        print(f\"âœ… Loaded model from: {config.MODEL_PATH}\")\n",
        "    else:\n",
        "        print(\"âš ï¸  No model found, starting from scratch\")\n",
        "        config.TRAIN = True"
      ],
      "metadata": {
        "id": "load_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Loop"
      ],
      "metadata": {
        "id": "training_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if config.TRAIN:\n",
        "    print(\"Starting training...\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    for epoch in range(config.EPOCHS):\n",
        "        print(f\"\\n--- Epoch {epoch+1}/{config.EPOCHS} ---\")\n",
        "\n",
        "        # Train for one epoch\n",
        "        avg_loss = train(\n",
        "            model=model,\n",
        "            dataloader=dataloader,\n",
        "            scheduler=scheduler,\n",
        "            optimizer=optimizer,\n",
        "            device=config.DEVICE,\n",
        "            epoch=epoch\n",
        "        )\n",
        "\n",
        "        print(f\"Epoch: {epoch+1} - Average loss: {avg_loss:.4f}\")\n",
        "\n",
        "        # Sample and evaluate\n",
        "        if (epoch + 1) % config.SAMPLE_EVERY == 0:\n",
        "            print(f\"---Sampling - epoch {epoch+1}\")\n",
        "\n",
        "            # Generate samples\n",
        "            generated_images = sampling(\n",
        "                model=model,\n",
        "                low_res_imgs=val_low_res_img,\n",
        "                scheduler=scheduler,\n",
        "                config=config\n",
        "            )\n",
        "\n",
        "            # Compute metrics\n",
        "            psnr = psnr_metric(generated_images, val_high_res_img)\n",
        "            ssim = ssim_metric(generated_images, val_high_res_img)\n",
        "            lpips_score = lpips_metric(generated_images, val_high_res_img)\n",
        "\n",
        "            print(f\"PSNR: {psnr:.2f} dB | SSIM: {ssim:.4f} | LPIPS: {lpips_score:.4f}\")\n",
        "\n",
        "            # Save samples and visualizations\n",
        "            visualize_and_save_samples(\n",
        "                generated_images=generated_images,\n",
        "                val_high_res_img=val_high_res_img,\n",
        "                val_low_res_img=val_low_res_img,\n",
        "                epoch=epoch+1,\n",
        "                config=config\n",
        "            )\n",
        "\n",
        "            # Save checkpoint\n",
        "            checkpoint_path = os.path.join(config.OUTPUT_DIR, f'model_epoch_{epoch+1}.pth')\n",
        "            torch.save({\n",
        "                'epoch': epoch+1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': avg_loss,\n",
        "                'psnr': psnr,\n",
        "                'ssim': ssim,\n",
        "                'lpips': lpips_score,\n",
        "            }, checkpoint_path)\n",
        "            print(f\"Checkpoint saved: {checkpoint_path}\")\n",
        "\n",
        "    # Save final model\n",
        "    final_model_path = os.path.join(config.OUTPUT_DIR, 'model.pth')\n",
        "    torch.save({\n",
        "        'epoch': config.EPOCHS,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "    }, final_model_path)\n",
        "    print(f\"\\nâœ… Training complete! Final model saved: {final_model_path}\")\n",
        "\n",
        "else:\n",
        "    print(\"Skipping training (config.TRAIN = False)\")"
      ],
      "metadata": {
        "id": "training_loop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation / Inference"
      ],
      "metadata": {
        "id": "eval_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate samples (works in both training and inference mode)\n",
        "print(\"Generating samples...\")\n",
        "\n",
        "generated_images = sampling(\n",
        "    model=model,\n",
        "    low_res_imgs=val_low_res_img,\n",
        "    scheduler=scheduler,\n",
        "    config=config\n",
        ")\n",
        "\n",
        "# Compute metrics\n",
        "psnr = psnr_metric(generated_images, val_high_res_img)\n",
        "ssim = ssim_metric(generated_images, val_high_res_img)\n",
        "lpips_score = lpips_metric(generated_images, val_high_res_img)\n",
        "\n",
        "print(f\"\\nğŸ“Š Evaluation Results:\")\n",
        "print(f\"PSNR:  {psnr:.2f} dB\")\n",
        "print(f\"SSIM:  {ssim:.4f}\")\n",
        "print(f\"LPIPS: {lpips_score:.4f}\")\n",
        "\n",
        "# Visualize\n",
        "visualize_and_save_samples(\n",
        "    generated_images=generated_images,\n",
        "    val_high_res_img=val_high_res_img,\n",
        "    val_low_res_img=val_low_res_img,\n",
        "    epoch='final',\n",
        "    config=config\n",
        ")"
      ],
      "metadata": {
        "id": "evaluation"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Additional Analysis (Optional)"
      ],
      "metadata": {
        "id": "analysis_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on larger test set (optional)\n",
        "num_test_samples = 32\n",
        "\n",
        "print(f\"Evaluating on {num_test_samples} samples...\")\n",
        "\n",
        "all_psnr = []\n",
        "all_ssim = []\n",
        "all_lpips = []\n",
        "\n",
        "for i, (high_res, low_res) in enumerate(dataloader):\n",
        "    if i >= num_test_samples // config.BATCH_SIZE:\n",
        "        break\n",
        "\n",
        "    high_res = high_res.to(config.DEVICE)\n",
        "    low_res = low_res.to(config.DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        generated = sampling(model, low_res, scheduler, config)\n",
        "\n",
        "    all_psnr.append(psnr_metric(generated, high_res))\n",
        "    all_ssim.append(ssim_metric(generated, high_res))\n",
        "    all_lpips.append(lpips_metric(generated, high_res))\n",
        "\n",
        "import numpy as np\n",
        "print(f\"\\nğŸ“Š Results on {num_test_samples} samples:\")\n",
        "print(f\"PSNR:  {np.mean(all_psnr):.2f} Â± {np.std(all_psnr):.2f} dB\")\n",
        "print(f\"SSIM:  {np.mean(all_ssim):.4f} Â± {np.std(all_ssim):.4f}\")\n",
        "print(f\"LPIPS: {np.mean(all_lpips):.4f} Â± {np.std(all_lpips):.4f}\")"
      ],
      "metadata": {
        "id": "analysis"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}