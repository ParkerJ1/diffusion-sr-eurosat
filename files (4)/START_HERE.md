# üöÄ START HERE - Project Setup Checklist

Welcome! This guide will help you set up your diffusion model project in the right order.

## üì¶ What You Have

I've created a complete project structure for you:

```
‚úÖ configs/config.py        - Configuration (extracted from notebook)
‚úÖ src/data/dataset.py      - Dataset classes (extracted from notebook)  
‚è≥ src/models/unet.py       - Template (you need to fill this in)
‚è≥ src/models/diffusion.py  - Template (you need to fill this in)
‚è≥ src/training/train.py    - Template (you need to fill this in)
‚è≥ src/training/sample.py   - Template (you need to fill this in)
‚è≥ Other modules             - Templates for remaining code
‚úÖ README.md                 - Project documentation
‚úÖ requirements.txt          - All dependencies
‚úÖ .gitignore                - Git ignore rules
‚úÖ SETUP_GUIDE.md            - Detailed setup instructions
‚úÖ EXTRACTION_GUIDE.md       - Code extraction instructions
```

---

## üéØ Step-by-Step Setup (Do in This Order!)

### ‚úÖ Step 1: Save This Folder Locally (5 minutes)

1. Download the entire `diffusion-sr-eurosat/` folder
2. Save it to your local machine (e.g., `~/projects/diffusion-sr-eurosat/`)
3. You should see all the files and folders listed above

### ‚úÖ Step 2: Extract Code from Notebook (1-2 hours)

**Two options:**

**Option A: Manual Extraction (Recommended)**
1. Open `EXTRACTION_GUIDE.md` - it shows exactly what code goes where
2. Open your original notebook (`notebooks/DiffusionSR_original.ipynb`)
3. Copy-paste code from notebook cells into the appropriate Python files
4. Start with the easiest ones first:
   - `src/models/diffusion.py` (just the Scheduler class)
   - `src/utils/helpers.py` (find_latest_model function)
   - `src/evaluation/metrics.py` (metrics classes)
   - `src/models/unet.py` (U-Net architecture)
   - `src/training/train.py` (training function)
   - `src/training/sample.py` (sampling function)
   - `src/utils/visualization.py` (visualization functions)

**Option B: Test That Imports Work First**
1. Don't extract everything at once
2. Start with just `configs/config.py` (already done)
3. Test that you can import it
4. Then extract one module at a time and test

### ‚úÖ Step 3: Test Imports Locally (15 minutes)

Create a test file `test_imports.py`:

```python
import sys
sys.path.append('.')

# Test imports
try:
    from configs.config import CONFIG
    print("‚úÖ Config imported")
except Exception as e:
    print(f"‚ùå Config import failed: {e}")

try:
    from src.data.dataset import get_dataloader
    print("‚úÖ Dataset imported")
except Exception as e:
    print(f"‚ùå Dataset import failed: {e}")

# Add more imports as you extract modules
```

Run it:
```bash
cd diffusion-sr-eurosat
python test_imports.py
```

### ‚úÖ Step 4: Create GitHub Repository (10 minutes)

1. Go to https://github.com ‚Üí New Repository
2. Name: `diffusion-sr-eurosat`
3. Make it **Private** (for now)
4. Don't initialize with README (you already have one)

Then on your local machine:
```bash
cd diffusion-sr-eurosat

# Initialize Git
git init
git add .
git commit -m "Initial project structure"

# Connect to GitHub
git remote add origin https://github.com/YOUR_USERNAME/diffusion-sr-eurosat.git
git branch -M main
git push -u origin main
```

### ‚úÖ Step 5: Test in Colab (15 minutes)

Create a new Colab notebook and test:

```python
# Cell 1: Clone from GitHub
!git clone https://github.com/YOUR_USERNAME/diffusion-sr-eurosat.git
%cd diffusion-sr-eurosat

# Cell 2: Install dependencies
!pip install -r requirements.txt

# Cell 3: Test imports
import sys
sys.path.append('.')

from configs.config import CONFIG
from src.data.dataset import get_dataloader
# Import other modules as you extract them

print("‚úÖ All imports work!")
```

### ‚úÖ Step 6: Update Your Workflow (Ongoing)

**From now on:**

1. **Edit code locally** (VS Code, Jupyter Lab, etc.)
   ```bash
   # Edit files
   git add .
   git commit -m "Add self-attention layer"
   git push
   ```

2. **Run in Colab**
   ```python
   %cd diffusion-sr-eurostat
   !git pull origin main  # Get latest changes
   # Run your training
   ```

3. **Iterate**
   - Make changes locally
   - Commit and push
   - Pull in Colab
   - Train on GPU

---

## üìö Reference Guides

- **SETUP_GUIDE.md** - Detailed project structure explanation
- **EXTRACTION_GUIDE.md** - Exact mapping of notebook cells ‚Üí Python files
- **README.md** - Project documentation
- **docs/experiment_log.md** - Template for tracking experiments

---

## üÜò Troubleshooting

### "ModuleNotFoundError: No module named 'configs'"
- Make sure you're in the project root directory
- Add `sys.path.append('.')` or `sys.path.append('..')` at top of notebook

### "ImportError: cannot import name 'ConditionalUNet'"
- You haven't extracted that code yet
- Check EXTRACTION_GUIDE.md for what needs to be extracted

### "Git push failed"
- Make sure you created the GitHub repository
- Check that the remote URL is correct: `git remote -v`

### "Files too large for GitHub"
- Checkpoints (`.pth` files) should be in `.gitignore`
- Check `.gitignore` includes `outputs/checkpoints/*.pth`

---

## ‚úÖ Final Checklist

Before you start training:

- [ ] Saved project folder locally
- [ ] Extracted all code from notebook to Python files
- [ ] Tested imports work locally
- [ ] Created GitHub repository
- [ ] Pushed code to GitHub
- [ ] Tested loading from GitHub in Colab
- [ ] Updated your workflow (edit local ‚Üí push ‚Üí pull in Colab)

---

## üéâ You're Ready!

Once you've completed all steps above, you have:
- ‚úÖ Professional project structure
- ‚úÖ Version control with GitHub
- ‚úÖ Clean separation of code and experiments
- ‚úÖ Ready for publication

**Now you can focus on the research!** üöÄ

---

## üìß Need Help?

If you get stuck, refer to:
1. EXTRACTION_GUIDE.md - for code extraction
2. SETUP_GUIDE.md - for detailed explanations
3. README.md - for usage examples

Good luck with your research! üî¨
